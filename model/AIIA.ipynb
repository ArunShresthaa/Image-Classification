{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494f5d7e-bdbc-4d7e-b42f-46febf1d0d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from torchvision import datasets, transforms, models\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb605d2-3e91-47dd-aa95-37277b37f4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "num_classes = 25\n",
    "batch_size = 64\n",
    "num_epochs = 50\n",
    "initial_lr = 0.001\n",
    "weight_decay = 1e-4\n",
    "dropout_rate = 0.5\n",
    "patience = 10  # for early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794bd152-00b5-425e-9130-04930086cec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98118160-828f-4169-a860-f34f3388df94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.downsample = None\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class CustomResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes=25):\n",
    "        super(CustomResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(512 * block.expansion, num_classes)\n",
    "        )\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        layers = []\n",
    "        layers.append(block(self.in_planes, planes, stride))\n",
    "        self.in_planes = planes\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(planes, planes))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "def custom_resnet18(num_classes=25):\n",
    "    return CustomResNet(BasicBlock, [2, 2, 2, 2], num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a54b8f-a370-4ccf-bc6b-7513b2f71eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomRotation(30),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.4731, 0.4819, 0.4018], std=[0.1925, 0.1915, 0.1963])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.4706, 0.4802, 0.4020], std=[0.1907, 0.1898, 0.1950])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c704a386-f179-4fa8-ac0d-677b8a3f38cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './Seen Datasets'\n",
    "image_datasets = {x: datasets.ImageFolder(root=f\"{data_dir}/{x}\", transform=data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "data_loaders = {x: data.DataLoader(image_datasets[x], batch_size=batch_size,\n",
    "                                   shuffle=True, num_workers=8, pin_memory=True)\n",
    "                for x in ['train', 'val']}\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b50e3e2-6faf-4c17-babf-447bf6680e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network\n",
    "model = custom_resnet18(num_classes=num_classes).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=initial_lr, weight_decay=weight_decay)\n",
    "scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=initial_lr, \n",
    "                                          steps_per_epoch=len(data_loaders['train']), epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccaf8bae-d52d-49b5-a636-c0093d7ce6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track history for plotting\n",
    "train_loss_history = []\n",
    "train_acc_history = []\n",
    "val_loss_history = []\n",
    "val_acc_history = []\n",
    "\n",
    "# Training the model with early stopping\n",
    "best_model_wts = None\n",
    "best_acc = 0.0\n",
    "early_stop_counter = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "    print('-' * 10)\n",
    "\n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            model.train()\n",
    "        else:\n",
    "            model.eval()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        for inputs, labels in tqdm(data_loaders[phase], desc=f\"{phase} - Epoch {epoch+1}\"):\n",
    "            inputs = inputs.to(device, non_blocking=True)\n",
    "            labels = labels.to(device, non_blocking=True)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "        if phase == 'train':\n",
    "            scheduler.step()\n",
    "            epoch_train_loss = running_loss / dataset_sizes['train']\n",
    "            epoch_train_corrects = running_corrects.double() / dataset_sizes['train']\n",
    "        else:\n",
    "            epoch_val_loss = running_loss / dataset_sizes['val']\n",
    "            epoch_val_corrects = running_corrects.double() / dataset_sizes['val']\n",
    "\n",
    "    train_loss_history.append(epoch_train_loss)\n",
    "    train_acc_history.append(epoch_train_corrects.item())\n",
    "    val_loss_history.append(epoch_val_loss)\n",
    "    val_acc_history.append(epoch_val_corrects.item())\n",
    "\n",
    "    print(f'Train Loss: {epoch_train_loss:.4f} Acc: {epoch_train_corrects:.4f}')\n",
    "    print(f'Val Loss: {epoch_val_loss:.4f} Acc: {epoch_val_corrects:.4f}')\n",
    "\n",
    "    if epoch_val_corrects > best_acc:\n",
    "        best_acc = epoch_val_corrects\n",
    "        best_model_wts = model.state_dict().copy()\n",
    "        early_stop_counter = 0\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "\n",
    "    if early_stop_counter >= patience:\n",
    "        print(\"Early stopping\")\n",
    "        model.load_state_dict(best_model_wts)\n",
    "        break\n",
    "\n",
    "print('Best val Acc: {:4f}'.format(best_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d7f326-e51b-49c9-85d9-01e9f75015b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model weights\n",
    "if best_model_wts:\n",
    "    model.load_state_dict(best_model_wts)\n",
    "\n",
    "# Save the entire model\n",
    "torch.save(model, 'best_bird_classifier_full.pth')\n",
    "print(\"Model saved with architecture and weights\")\n",
    "\n",
    "# Plot the training curves\n",
    "epochs = len(train_loss_history)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot the loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(epochs), train_loss_history, label='Train Loss')\n",
    "plt.plot(range(epochs), val_loss_history, label='Val Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot the accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(epochs), train_acc_history, label='Train Accuracy')\n",
    "plt.plot(range(epochs), val_acc_history, label='Val Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
